Lyricalabs Nexa Python KÃ¼tÃ¼phanesi

Lyricalabs Nexa, Lyrica Labs tarafÄ±ndan geliÅŸtirilen geniÅŸ veri LLM modellerine eriÅŸim saÄŸlayan Python kÃ¼tÃ¼phanesidir. Bu kÃ¼tÃ¼phane ile Nexa modellerini kolayca kullanabilirsiniz.

ğŸ“¦ Kurulum

```bash
pip install lyricalabs_nexa
```

ğŸ”‘ API Token Alma

KÃ¼tÃ¼phaneyi kullanmak iÃ§in API token'a ihtiyacÄ±nÄ±z var:

1. Lyricalabs Platform adresine girin
2. KayÄ±t olun ve giriÅŸ yapÄ±n
3. Dashboard'dan API token'Ä±nÄ±zÄ± alÄ±n

ğŸš€ HÄ±zlÄ± BaÅŸlangÄ±Ã§

```python
from lyricalabs_nexa import NexaClient

# API token'Ä±nÄ±z ile client oluÅŸturun
client = NexaClient(token="API_TOKENÄ°NÄ°Z")

# KullanÄ±labilir modelleri listeleyin
print("Mevcut modeller:")
for model in client.list_models():
    print(f"  â€¢ {model}")

# Metin Ã¼retimi
response = client.generate_text(
    prompt="Python'da yapay zeka uygulamalarÄ± nasÄ±l geliÅŸtirilir?",
    model="nexa-7.0-express"
)

print("YanÄ±t:", response["choices"][0]["text"])
```

ğŸ“š Model Listesi

Genel AmaÃ§lÄ± Modeller

Model AÃ§Ä±klama Ã–nerilen KullanÄ±m
nexa-5.0-preview Genel amaÃ§lÄ±, dengeli model Her tÃ¼rlÃ¼ metin Ã¼retimi
nexa-3.7-pro Ä°ÅŸ odaklÄ±, profesyonel Ã§Ä±ktÄ±lar Rapor, e-posta, belge
nexa-6.1-infinity BÃ¼yÃ¼k baÄŸlam, detaylÄ± analiz Uzun form iÃ§erik, analiz
nexa-7.0-insomnia 24/7 optimize edilmiÅŸ, yÃ¼ksek performans, empati ve insan anlama kapasitesine sahip Duygusal iÃ§erik, destek sistemi

Ã–zel AmaÃ§lÄ± Modeller

Model AÃ§Ä±klama Ã–nerilen KullanÄ±m
nexa-5.0-intimate YaratÄ±cÄ± yazÄ±m ve duygusal iÃ§erik Hikaye, ÅŸiir, yaratÄ±cÄ± yazÄ±
nexa-6.1-code-llm Kod yazma ve analiz iÃ§in Ã¶zel Programlama, kod analizi
nexa-7.0-express HÄ±zlÄ± yanÄ±t, dÃ¼ÅŸÃ¼k gecikme Chat, hÄ±zlÄ± yanÄ±t gerektiren uygulamalar
gpt-5-mini-chatgpt ChatGPT uyumlu mini model ChatGPT benzeri uygulamalar

ğŸ¯ Ã–rnek KullanÄ±mlar

Insomnia Modeli ile Duygusal Destek

```python
# Insomnia modeli - empati ve insan anlama kapasitesine sahip
response = client.generate_text(
    prompt="Kendimi yalnÄ±z hissediyorum, ne yapmalÄ±yÄ±m?",
    model="nexa-7.0-insomnia",
    temperature=0.7,
    max_tokens=500
)
print(response["choices"][0]["text"])
```

Kod Ãœretimi

```python
response = client.generate_text(
    prompt="Python'da REST API oluÅŸturan bir Flask uygulamasÄ± yaz",
    model="nexa-6.1-code-llm",
    temperature=0.3,
    max_tokens=1000
)
```

Stream Modu ile GerÃ§ek ZamanlÄ± YanÄ±t

```python
for chunk in client.generate_text(
    prompt="Ä°klim deÄŸiÅŸikliÄŸi hakkÄ±nda bilgi ver",
    model="nexa-6.1-infinity",
    stream=True,
    max_tokens=800
):
    print(chunk, end="", flush=True)
```

Ã–zel Sistem TalimatÄ±

```python
response = client.generate_text(
    prompt="En iyi programlama dili hangisidir?",
    model="nexa-3.7-pro",
    custom_system_instruction="Sen tarafsÄ±z bir teknoloji uzmanÄ±sÄ±n. Her dilin avantajlarÄ±nÄ± ve dezavantajlarÄ±nÄ± objektif ÅŸekilde aÃ§Ä±kla.",
    temperature=0.5
)
```

âš™ï¸ Parametreler

```python
response = client.generate_text(
    prompt="Soru veya talimatÄ±nÄ±z",
    model="nexa-5.0-preview",      # KullanÄ±lacak model
    temperature=0.7,               # YaratÄ±cÄ±lÄ±k (0-2, yÃ¼ksek deÄŸer = daha yaratÄ±cÄ±)
    max_tokens=1024,               # Max Ã¼retilecek token sayÄ±sÄ±
    top_p=0.95,                    # Ã‡eÅŸitlilik kontrolÃ¼
    frequency_penalty=0.2,         # Tekrar cezasÄ±
    presence_penalty=0.1,          # Yeni konu Ã¶dÃ¼lÃ¼
    stream=False                   # Stream modu
)
```

ğŸ” Model Bilgisi Alma

```python
# TÃ¼m modelleri aÃ§Ä±klamalarÄ±yla listeleyin
models = client.list_models(with_descriptions=True)
for model, desc in models.items():
    print(f"{model}: {desc}")

# Belirli bir model hakkÄ±nda detaylÄ± bilgi
model_info = client.get_model_info("nexa-7.0-insomnia")
print(f"""
Model: {model_info['name']}
AÃ§Ä±klama: {model_info['description']}
Kategori: {model_info['category']}
""")
```

ğŸ©º Sistem SaÄŸlÄ±k KontrolÃ¼

```python
# API baÄŸlantÄ±nÄ±zÄ± test edin
health = client.health_check()
if health["status"] == "healthy":
    print("âœ… API'ye baÄŸlantÄ± baÅŸarÄ±lÄ±!")
    print(f"ğŸ“Š Mevcut model sayÄ±sÄ±: {health['models_available']}")
else:
    print("âŒ API baÄŸlantÄ±sÄ± sorunlu:", health["error"])
```

ğŸ› ï¸ GeliÅŸmiÅŸ Ã–zellikler

Toplu Ä°ÅŸlem

```python
prompts = [
    "Python'Ä±n avantajlarÄ± nelerdir?",
    "JavaScript neden popÃ¼ler?",
    "Go dili ne iÃ§in kullanÄ±lÄ±r?"
]

results = client.batch_generate(
    prompts=prompts,
    model="nexa-5.0-preview",
    max_tokens=300
)
```

Ã–zel API Endpoint

```python
# Ã–zel bir endpoint kullanmak isterseniz
client = NexaClient(
    token="API_TOKENÄ°NÄ°Z",
    base_url="https://api-lyricalabs.vercel.app/v4/llm/nexa/generative/model/completions"
)
```

â“ SÄ±k Sorulan Sorular

1. API token'Ä±mÄ± nasÄ±l alÄ±rÄ±m?

Lyricalabs Platform adresinden kayÄ±t olun ve dashboard'dan token oluÅŸturun.

2. Hangi modeli kullanmalÄ±yÄ±m?

Â· Genel kullanÄ±m: nexa-5.0-preview
Â· Duygusal iÃ§erik: nexa-7.0-insomnia (empati Ã¶zellikli)
Â· Kod yazma: nexa-6.1-code-llm
Â· HÄ±zlÄ± yanÄ±t: nexa-7.0-express

3. Rate limit var mÄ±?

Evet, token tipinize gÃ¶re deÄŸiÅŸir. Detaylar iÃ§in dashboard'Ä±nÄ±zÄ± kontrol edin.

4. Hata alÄ±yorum, ne yapmalÄ±yÄ±m?

```python
try:
    response = client.generate_text(...)
except Exception as e:
    print(f"Hata: {e}")
    # Health check yapÄ±n
    print(client.health_check())
```

ğŸ“ Destek ve Ä°letiÅŸim

Â· Website: lyricalabs.vercel.app
Â· Nexa API Docs: lyricalabs.vercel.app/docs
Â· Email: lyricalabs@gmail.com
Â· GitHub Issues: Sorun bildirin

ğŸ“„ Lisans

MIT License. Detaylar iÃ§in LICENSE dosyasÄ±na bakÄ±n.

---

Not: Insomnia modeli (nexa-7.0-insomnia) Ã¶zellikle empati ve insan anlama kapasitesi Ã¼zerine optimize edilmiÅŸtir. Duygusal destek, danÄ±ÅŸmanlÄ±k ve insan etkileÅŸimi gerektiren uygulamalar iÃ§in idealdir.

ğŸ’™ Hizmetlerimize eriÅŸmek iÃ§in kayÄ±t olun
